{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826b5c63-331a-47d0-8084-512412c995c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional,Conv1D, MaxPooling1D, Flatten, BatchNormalization, Input, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from urllib.parse import urlparse # Number of subdomains in the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac176d9-3f1b-4fae-917f-79c609d37408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"phisingmodel.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f2a3dc-6ee0-430a-9273-f91ac73d7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sender domain \n",
    "def separate_senderdomain(text):\n",
    "    domain = re.findall(r'<(.*?)>', text)\n",
    "\n",
    "    if not domain:\n",
    "        domain.append('unknown')\n",
    "    return ''.join(domain)\n",
    "\n",
    "def extract_url(text):\n",
    "\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    text_without_urls = re.sub(url_pattern, 'url', text)\n",
    "    return text_without_urls,urls\n",
    "\n",
    "\n",
    "def extract_url_features(url):\n",
    "    features = []\n",
    "\n",
    "    features.append(1 if url.lower().startswith(\"https\") else 0)\n",
    "\n",
    "    features.append(len(url))\n",
    "\n",
    "    try:\n",
    "        parsed_url=urlparse(url)\n",
    "        subdomain_count = len(parsed_url.netloc.split('.')) -2 #subdomains count, excluding domain and top level domain\n",
    "        features.append(subdomain_count)\n",
    "    except Exception as e:\n",
    "        features.append(0)\n",
    "\n",
    "    suspicious_keywords = [\"login\", \"verify\", \"account\", \"secure\", \"update\",\"password\"]\n",
    "    features.append(1 if any(keyword in url.lower() for keyword in suspicious_keywords) else 0)\n",
    "\n",
    "    features.append(url.count('?'))\n",
    "\n",
    "    return features\n",
    "\n",
    "def extract_features_from_urls(urls):\n",
    "    all_features =[]\n",
    "\n",
    "    for url in urls:\n",
    "        features = extract_url_features(url)\n",
    "        all_features.append(features)\n",
    "\n",
    "    if all_features:\n",
    "        aggregated_features = []\n",
    "        for i in range(len(all_features[0])):\n",
    "            if isinstance(all_features[0][i], (int,float)):\n",
    "                aggregated_features.append(sum(f[i] for f in all_features) / len(all_features))\n",
    "            else:\n",
    "                aggregated_features.append(None)\n",
    "        return aggregated_features\n",
    "    else:\n",
    "        return [0*5]\n",
    "\n",
    "#clean body and subject\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>','',text)        # remove the HTML tags\n",
    "    text = re.sub(r'http\\S+|www\\S+','',text) # remove URLS\n",
    "    text = re.sub(r'[^\\w\\s]','',text) # remove alpha numeric\n",
    "    text = text.lower().strip() # strip trailing whitespace\n",
    "    return text\n",
    "\n",
    "def remove_slashN(text):\n",
    "    text = text.replace('\\n',' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "921d2942-2435-45ef-92fa-6989c44b0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = pd.DataFrame({'sender':['cPanel <service@cpanel.com>', 'MR. JAMES NGOLA. <james_ngola2002@maktoob.com>'],\n",
    "                            'body':['Congratulations! You\\'ve won a $1000 gift card! Click here to claim your prize: https://fakeurl.com/','Hi Team,I hope this message finds you well. I wanted to remind you about our upcoming meeting scheduled for Thursday, March 15th at 10:00 AM. We will be discussing the latest updates on the project and addressing any questions or concerns you may have.'],\n",
    "                           'subject':['YOU HAVE WON A LOTTERY','Meeting Reminder: Project Update'],\n",
    "                           'urls':[1,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3aedf4-a835-4af7-b648-541920908ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>body</th>\n",
       "      <th>subject</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cPanel &lt;service@cpanel.com&gt;</td>\n",
       "      <td>Congratulations! You've won a $1000 gift card!...</td>\n",
       "      <td>YOU HAVE WON A LOTTERY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MR. JAMES NGOLA. &lt;james_ngola2002@maktoob.com&gt;</td>\n",
       "      <td>Hi Team,I hope this message finds you well. I ...</td>\n",
       "      <td>Meeting Reminder: Project Update</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sender  \\\n",
       "0                     cPanel <service@cpanel.com>   \n",
       "1  MR. JAMES NGOLA. <james_ngola2002@maktoob.com>   \n",
       "\n",
       "                                                body  \\\n",
       "0  Congratulations! You've won a $1000 gift card!...   \n",
       "1  Hi Team,I hope this message finds you well. I ...   \n",
       "\n",
       "                            subject  urls  \n",
       "0            YOU HAVE WON A LOTTERY     1  \n",
       "1  Meeting Reminder: Project Update     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7a4daf-dd80-43f8-a3cb-950190231197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_process(testDataset):\n",
    "    # get the sender domain\n",
    "    testDataset['senderdomain'] = testDataset['sender'].apply(separate_senderdomain)\n",
    "\n",
    "    # separate the url and body\n",
    "    testDataset['body'], testDataset['extracted_url'] = zip(*testDataset['body'].apply(extract_url))\n",
    "    testDataset['num_urls'] = testDataset['extracted_url'].apply(len)\n",
    "\n",
    "    # extracting feature of urls\n",
    "    testDataset['extracted_url'] = testDataset['extracted_url'].apply(extract_features_from_urls)\n",
    "\n",
    "    #clean subject and body\n",
    "    testDataset['clean_body'] = testDataset['body'].apply(clean_text)\n",
    "    testDataset['clean_subject'] = testDataset['subject'].apply(clean_text)\n",
    "\n",
    "    testDataset['clean_body'] = testDataset['clean_body'].apply(remove_slashN)\n",
    "\n",
    "    testDataset['clean_body_len'] = testDataset['clean_body'].apply(len)\n",
    "    testDataset['combined_text'] = testDataset['senderdomain'] + \" \" + testDataset['clean_subject'] + \" \" +testDataset['clean_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f8cbe7d-67eb-4eb4-8ffa-befca950d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_process(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3aff04-9d60-4bf6-b4a4-f3e2bdb2ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testDataset):\n",
    "    texts = testDataset['combined_text'].values\n",
    "    num_urls = testDataset['num_urls'].values.reshape(-1, 1)\n",
    "    body_len = testDataset['clean_body_len'].values.reshape(-1, 1)\n",
    "    extracted_url = testDataset['extracted_url'].values.reshape(-1,1)\n",
    "\n",
    "    vocab_size = 10000\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    #text_length = [len(seq) for seq in sequences]\n",
    "    #max_length = np.percentile(text_length,95)\n",
    "    #print(max_length)\n",
    "\n",
    "    X_padded = pad_sequences(sequences, maxlen=659, padding='post', truncating='post')\n",
    "\n",
    "    extracted_url = [x[0] if isinstance(x[0], list) else [x[0]] for x in extracted_url]\n",
    "    MAX_URL_LENGTH = 5  # Choose based on your data analysis\n",
    "    extracted_url_padded = pad_sequences(extracted_url, maxlen=MAX_URL_LENGTH, padding='post', dtype='float32')\n",
    "\n",
    "    y_pred = model.predict([X_padded,num_urls,body_len,extracted_url_padded])\n",
    "    print ([\"NotSpam\" if y > 0.5 else 'Spam' for y in y_pred.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac2d4d5-279e-4d9a-a7a6-72671912dcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "['Spam', 'NotSpam']\n"
     ]
    }
   ],
   "source": [
    "predict(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73637323-8a41-4bf2-bfd2-28a7a5753cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09cce9-2aa9-4c89-afa1-ceb39ca0ea6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
